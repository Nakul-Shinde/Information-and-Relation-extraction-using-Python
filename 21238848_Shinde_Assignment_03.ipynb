{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHfQMjDnlACs"
   },
   "source": [
    "# Assignment 3 - CT5120/CT5146\n",
    "\n",
    "### Instructions:\n",
    "- Complete all the tasks below and upload your submission as a Python notebook on Blackboard with the filename “`StudentID_Lastname.ipynb`” before **23:59** on **December 31, 2021**. Please note that there will be no further extensions to this deadline and we highly encourage you to submit this assignment before Semester 1 exams.\n",
    "- This is an individual assignment, you **must not** work with other students to complete this assessment.\n",
    "- The assignment is worth $100$ marks and constitutes 19% of the final grade. The breakdown of the marking scheme for each task is as follows:\n",
    "\n",
    "|           | Task | Marks |\n",
    "| :---      | :-----| -----:|\n",
    "| Task 1    | Pre-processing |   15 |\n",
    "| Task 2    | Named Entity Recognition |    10 |\n",
    "| Task 3    | Information / Relation Extraction (I) | 30 |\n",
    "| Task 4    | Information / Relation Extraction (II) | 15 |\n",
    "| Task 5    | Combining information in the output   | 5 |\n",
    "| Task 6    | Evaluation (I) | 15 |\n",
    "| Task 7    | Evaluation (II) | 10 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEpjx2qKnyBl"
   },
   "source": [
    "---\n",
    "\n",
    "## Information Extraction and Relation Extraction\n",
    "\n",
    "In the following tasks you will write code to perform **_information extraction_** and **_relation extraction_** across a collection of documents in `movies.zip`.\n",
    "\n",
    "The zip archive contains 100 files, out of which 50 are plaintext documents and other 50 contain data structured as JSON.\n",
    "Each plaintext document contains a text description of a movie taken from the English version of Wikipedia, while each JSON document contains *gold-standard* labels (also called *reference* labels) stored as key-value pairs for the entities and relations for each document.\n",
    "\n",
    "You are only allowed to use the given documents and labels and **must not** use any other external sources of data for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64euw8hXygah"
   },
   "source": [
    "---\n",
    "\n",
    "Download and unarchive `movies.zip` from Blackboard and place it in the same location as this notebook or uncomment the code cell below to get the data in a directory called `movies` and also place it automatically in the same location as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXzoZVNZyevs"
   },
   "outputs": [],
   "source": [
    "!if test -f \"movies.zip\"; then rm \"movies.zip\"; fi\n",
    "!if test -d \"movies/\"; then rm -rf \"movies/\"; fi\n",
    "!wget \"https://drive.google.com/uc?export=download&id=1L6NcSGkubNJaL6xSnYEZZKSrlyXq1AbB\" -O \"movies.zip\"\n",
    "!unzip \"movies.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm1emJILzF5K"
   },
   "source": [
    "---\n",
    "\n",
    "## Reading Data\n",
    "\n",
    "Place the unzipped `movies` directory in the same location as this notebook and run the following code cell to read the plaintext and JSON documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "P5hzct-HzUvJ"
   },
   "outputs": [],
   "source": [
    "######### DO NOT EDIT THIS CELL #########\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "documents = []   # store the text documents as a list of strings\n",
    "labels = []      # store the gold-standard labels as a list of dictionaries\n",
    "\n",
    "for idx in range(50):\n",
    "  with open(os.path.join('movies', str(idx+1).zfill(2) + '.doc.txt')) as f:\n",
    "    doc = f.read().strip()\n",
    "  with open(os.path.join('movies', str(idx+1).zfill(2) + '.info.json')) as f:\n",
    "    label = json.load(f)\n",
    "\n",
    "  documents.append(doc)\n",
    "  labels.append(label)\n",
    "\n",
    "assert len(documents) == 50\n",
    "assert len(labels) == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnmnLhDyj2eG"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPCKvyYFj0zG",
    "outputId": "f123f25e-9509-4398-c887-34f353807b58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the libraries which might be useful\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('all', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "899-kd7LmlFp"
   },
   "source": [
    "---\n",
    "\n",
    "## Task 1: Document Pre-processing (15 Marks)\n",
    "Write a function that takes a document and returns a list of sentences with part-of-speech tags.\n",
    "\n",
    "The expected output is a list of tagged sentences where each tagged sentence is a list containing `(token, tag)` pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "dB8R43AklZxO"
   },
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "  '''Return a list of sentences tagged with part-of-speech tags for the given document.'''\n",
    "\n",
    "  tagged_sentences = []\n",
    "\n",
    "  # your code goes here\n",
    "  # ...\n",
    "  sentences = nltk.sent_tokenize(document)\n",
    "\n",
    "# Step 2: Tokenize sentences into words.\n",
    "  tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# Step 3: POS tagging.\n",
    "  tagged_sentences = [nltk.pos_tag(sent) for sent in tokenized_sentences]\n",
    "\n",
    "  return tagged_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KJLD-AMMvdq"
   },
   "source": [
    "Run the cell below to check if the output is formatted correctly.\n",
    "\n",
    "Expected output: `[('It', 'PRP'), ('received', 'VBD'), ('ten', 'JJ'), ('Oscar', 'NNP'), ('nominations', 'NNS'), ('(', '('), ('including', 'VBG'), ('Best', 'NNP'), ('Picture', 'NN'), (')', ')'), (',', ','), ('winning', 'VBG'), ('seven', 'CD'), ('.', '.')]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9sEQYa3TBDYE",
    "outputId": "d4fcb94a-bb22-41aa-c38c-ff44e6645e07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " ('received', 'VBD'),\n",
       " ('ten', 'JJ'),\n",
       " ('Oscar', 'NNP'),\n",
       " ('nominations', 'NNS'),\n",
       " ('(', '('),\n",
       " ('including', 'VBG'),\n",
       " ('Best', 'NNP'),\n",
       " ('Picture', 'NN'),\n",
       " (')', ')'),\n",
       " (',', ','),\n",
       " ('winning', 'VBG'),\n",
       " ('seven', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check output for Task 1\n",
    "ie_preprocess(documents[0])[-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgEPCLXmq8bC"
   },
   "source": [
    "## Task 2: Named Entity Recognition (10 Marks)\n",
    "\n",
    "Write a function that returns a list of all the named entities in a given document. The document here is structured as a list of sentences and tagged with part-of-speech tags.\n",
    "\n",
    "Hint: Set `binary = True` while calling the `ne_chunk` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "qHKjz5TKp5uM"
   },
   "outputs": [],
   "source": [
    "def find_named_entities(tagged_document):\n",
    "  '''Return a list of all the named entities in the given tagged document.'''\n",
    "  \n",
    "  # your code goes here\n",
    "  # ...\n",
    "  named_entities = []\n",
    "  \n",
    "  tree = nltk.ne_chunk_sents(tagged_document, binary=True)\n",
    "  for tree in tree:\n",
    "    for subtree in tree.subtrees():\n",
    "      if subtree.label() == \"NE\":\n",
    "        entity = \"\"\n",
    "        for leaf in subtree.leaves():\n",
    "          entity = entity + leaf[0] + \" \"\n",
    "        named_entities.append(entity.strip())\n",
    "\n",
    "  return named_entities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvZNyV-ENDZc"
   },
   "source": [
    "Run the cell below to check if the output is formatted correctly.\n",
    "\n",
    "The output values might not match exactly, but should look similar to: `['Star Wars', 'Star Wars', 'New Hope', 'American', 'George Lucas', 'Lucasfilm', ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnlqsKg7sk29",
    "outputId": "e82b97fb-2075-45ef-fe8e-d26ba18f2404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Star Wars',\n",
       " 'Star Wars',\n",
       " 'New Hope',\n",
       " 'American',\n",
       " 'George Lucas',\n",
       " 'Lucasfilm',\n",
       " 'Century Fox',\n",
       " 'Mark Hamill',\n",
       " 'Harrison Ford',\n",
       " 'Carrie Fisher']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check output for Task 2\n",
    "tagged_document = ie_preprocess(documents[0]) # pre-process the first document\n",
    "find_named_entities(tagged_document)[:10]     # display the first 10 named entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmpuu0yvwI_X"
   },
   "source": [
    "## Task 3: Information / Relation Extraction (I) (30 Marks)\n",
    "\n",
    "Choose any **three** relations out of the following and write functions to extract them from a given document.\n",
    "\n",
    "* **Title**\n",
    "* **Language**\n",
    "* **Starring**\n",
    "* **Release date**\n",
    "* **Cinematography**\n",
    "* **Dialogue by**\n",
    "* **Directed by**\n",
    "* **Edited by**\n",
    "* **Music by**\n",
    "* **Narrated by**\n",
    "* **Produced by**\n",
    "* **Screenplay by**\n",
    "* **Story by**\n",
    "* **Written by**\n",
    "* **Production companies**\n",
    "* **Distribution companies**\n",
    "* **Budget**\n",
    "* **Box office**\n",
    "\n",
    "\n",
    "The functions you define here must take as input a string called `document` and return the information/relation extracted as a list. You can explain your approach with comments along with your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Yw8YQAr-wwFM"
   },
   "outputs": [],
   "source": [
    "#Approach-\n",
    "#Firstly,a regular expression pattern which is a string  is compiled  into a regex pattern object which is later used to search for a match. \n",
    "#then from  every single sentence in tagged document tree object is generated using nltk.ne_chunk() function. \n",
    "#furthermore these tree objects are spiltted into a list of two-member lists, which consists of a string followed by a Named Entity.\n",
    "#This is done by tree2semi_rel() function. Then semi_rel2reldict() function converts these pairs into a dictionary of the subject and object NEs.\n",
    "#filter() function is then filter out the pattern (subjectNE...selected_pattern(produced)....objectNE) from the output of function semi_rel2reldict().\n",
    "#This ouput is appended to a list by removing  underscore and making the first letter uppercase. replace() and title() functions used for this purpose.\n",
    "\n",
    "def extract_producer_name(document):\n",
    "\n",
    " subject_class_entity = 'NE'\n",
    " object_class_entity = 'NE'\n",
    " searched_pattern_word = re.compile(r'.*\\bproduced\\b.*',re.IGNORECASE)             # Pattern for searching of a sentence\n",
    "\n",
    "\n",
    " producer_namelist = []\n",
    " sentence_tagged = ie_preprocess(document)                                    # Tagging of sentence using ie_preprocess() function\n",
    "\n",
    " for single_tagged_sent in sentence_tagged:\n",
    "\n",
    "  sentence_chunked = nltk.ne_chunk(single_tagged_sent, binary = True)                           # Chunking of sentnece to generate tree object\n",
    "  pair_extraction_task = nltk.sem.relextract.tree2semi_rel(sentence_chunked)                            # Extracting pair from chunked sentence\n",
    "  relation_dictionary_extract = nltk.sem.relextract.semi_rel2reldict(pair_extraction_task + [[[]]])     # Creation of reldict using extrated pair\n",
    "\n",
    "\n",
    "  pattern_filter = lambda sentence: (sentence['subjclass'] == subject_class_entity and searched_pattern_word.match(sentence['filler']) and sentence['objclass'] == object_class_entity)\n",
    "\n",
    "  relation_load = list(filter(pattern_filter, relation_dictionary_extract))                     #filtering pattern\n",
    "\n",
    "  for rel in relation_load:\n",
    "    producer_namelist.append(rel['objsym'].replace(\"_\", \" \").title())                               #Removing underscore and Uppercasing first letter\n",
    "    \n",
    " return producer_namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "N0mCY154fdHr"
   },
   "outputs": [],
   "source": [
    "#Approach-\n",
    "#Firstly,a regular expression pattern which is a string  is compiled  into a regex pattern object which is later used to search for a match. \n",
    "#then from  every single sentence in tagged document tree object is generated using nltk.ne_chunk() function. \n",
    "#furthermore these tree objects are spiltted into a list of two-member lists, which consists of a string followed by a Named Entity.\n",
    "#This is done by tree2semi_rel() function. Then semi_rel2reldict() function converts these pairs into a dictionary of the subject and object NEs.\n",
    "#filter() function is then filter out the pattern (subjectNE...selected_pattern(directed)....objectNE) from the output of function semi_rel2reldict().\n",
    "#This ouput is appended to a list by removing  underscore and making the first letter uppercase. replace() and title() functions used for this purpose.\n",
    "\n",
    "def extract_director_name(document):\n",
    "\n",
    " subject_class_entity = 'NE'\n",
    " object_class_entity = 'NE'\n",
    " searched_pattern_word = re.compile(r'.*\\bdirected\\b.*',re.IGNORECASE)                   # Pattern for searching of a sentence\n",
    "\n",
    "\n",
    " director_namelist = []\n",
    " sentence_tagged = ie_preprocess(document)                                            # Tagging of sentence using ie_preprocess() function\n",
    "\n",
    " for single_tagged_sent in sentence_tagged:\n",
    "\n",
    "  sentence_chunked = nltk.ne_chunk(single_tagged_sent, binary = True)                           # Chunking of sentnece to generate tree object\n",
    "  pair_extraction_task = nltk.sem.relextract.tree2semi_rel(sentence_chunked)                            # Extracting pair from chunked sentence\n",
    "  relation_dictionary_extract = nltk.sem.relextract.semi_rel2reldict(pair_extraction_task + [[[]]])     # Creation of reldict using extrated pair\n",
    "\n",
    "\n",
    "  pattern_filter = lambda sentence: (sentence['subjclass'] == subject_class_entity and searched_pattern_word.match(sentence['filler']) and sentence['objclass'] == object_class_entity)\n",
    "\n",
    "  relation_load = list(filter(pattern_filter, relation_dictionary_extract))                   #filtering pattern\n",
    "\n",
    "  for rel in relation_load:\n",
    "    director_namelist.append(rel['objsym'].replace(\"_\", \" \").title())                              #Removing underscore and Uppercasing first letter\n",
    "    \n",
    " return director_namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "vWWqBddOfxpO"
   },
   "outputs": [],
   "source": [
    "#Approach-\n",
    "#Firstly,a regular expression pattern which is a string  is compiled  into a regex pattern object which is later used to search for a match. \n",
    "#then from  every single sentence in tagged document tree object is generated using nltk.ne_chunk() function. \n",
    "#furthermore these tree objects are spiltted into a list of two-member lists, which consists of a string followed by a Named Entity.\n",
    "#This is done by tree2semi_rel() function. Then semi_rel2reldict() function converts these pairs into a dictionary of the subject and object NEs.\n",
    "#filter() function is then filter out the pattern (subjectNE...selected_pattern(written)....objectNE) from the output of function semi_rel2reldict().\n",
    "#This ouput is appended to a list by removing  underscore and making the first letter uppercase. replace() and title() functions used for this purpose.\n",
    "\n",
    "def extract_writer_name(document):\n",
    "\n",
    " subject_class_entity = 'NE'\n",
    " object_class_entity = 'NE'\n",
    " searched_pattern_word = re.compile(r'.*\\bwritten\\b.*',re.IGNORECASE)                            # Pattern for searching of a sentence\n",
    "\n",
    "\n",
    " writer_namelist = []\n",
    " sentence_tagged = ie_preprocess(document)                                                  # Tagging of sentence using ie_preprocess() function\n",
    "\n",
    " for single_tagged_sent in sentence_tagged:\n",
    "\n",
    "  sentence_chunked = nltk.ne_chunk(single_tagged_sent, binary = True)                             # Chunking of sentnece to generate tree object\n",
    "  pair_extraction_task = nltk.sem.relextract.tree2semi_rel(sentence_chunked)                              # Extracting pair from chunked sentence\n",
    "  relation_dictionary_extract = nltk.sem.relextract.semi_rel2reldict(pair_extraction_task + [[[]]])       # Creation of reldict using extrated pair\n",
    "\n",
    "\n",
    "  pattern_filter = lambda sentence: (sentence['subjclass'] == subject_class_entity and searched_pattern_word.match(sentence['filler']) and sentence['objclass'] == object_class_entity)\n",
    "\n",
    "  relation_load = list(filter(pattern_filter, relation_dictionary_extract))                     #filtering pattern\n",
    "\n",
    "  for rel in relation_load:\n",
    "    writer_namelist.append(rel['objsym'].replace(\"_\", \" \").title())                                 #Removing underscore and Uppercasing first letter\n",
    "    \n",
    " return writer_namelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuJmr-eKvrQ3"
   },
   "source": [
    "---\n",
    "\n",
    "## Task 4: Information / Relation Extraction (II)  (15 Marks)\n",
    "\n",
    "Identify one other relation of your choice, besides the ones mentioned in the previous task, and write a function to extract it. \n",
    "\n",
    "The function you define here must take as input a string called `document` and return the information/relations extracted as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "6q60FqoWgdab"
   },
   "outputs": [],
   "source": [
    "#Approach-\n",
    "#Firstly,a regular expression pattern which is a string  is compiled  into a regex pattern object which is later used to search for a match. \n",
    "#then from  every single sentence in tagged document tree object is generated using nltk.ne_chunk() function. \n",
    "#furthermore these tree objects are spiltted into a list of two-member lists, which consists of a string followed by a Named Entity.\n",
    "#This is done by tree2semi_rel() function. Then semi_rel2reldict() function converts these pairs into a dictionary of the subject and object NEs.\n",
    "#filter() function is then filter out the pattern (subjectNE...selected_pattern(awards)....objectNE) from the output of function semi_rel2reldict().\n",
    "#This ouput is appended to a list by removing  underscore and making the first letter uppercase. replace() and title() functions used for this purpose.\n",
    "\n",
    "def extract_award_names(document):\n",
    "\n",
    " subject_class_entity = 'NE'\n",
    " object_class_entity = 'NE'\n",
    " searched_pattern_word = re.compile(r'.*\\bawards\\b.*',re.IGNORECASE)                             # Pattern for searching of a sentence\n",
    "\n",
    "\n",
    " award_namelist = []\n",
    " sentence_tagged = ie_preprocess(document)                                                  # Tagging of sentence using ie_preprocess() function\n",
    "\n",
    " for single_tagged_sent in sentence_tagged:\n",
    "\n",
    "  sentence_chunked = nltk.ne_chunk(single_tagged_sent, binary = True)                             # Chunking of sentnece to generate tree object\n",
    "  pair_extraction_task = nltk.sem.relextract.tree2semi_rel(sentence_chunked)                              # Extracting pair from chunked sentence\n",
    "  relation_dictionary_extract = nltk.sem.relextract.semi_rel2reldict(pair_extraction_task + [[[]]])       # Creation of reldict using extrated pair\n",
    "\n",
    "\n",
    "  pattern_filter = lambda sentence: (sentence['subjclass'] == subject_class_entity and searched_pattern_word.match(sentence['filler']) and sentence['objclass'] == object_class_entity)\n",
    "\n",
    "  relation_load = list(filter(pattern_filter, relation_dictionary_extract))                       #filtering pattern\n",
    "\n",
    "  for rel in relation_load:\n",
    "    award_namelist.append(rel['objsym'].replace(\"_\", \" \").title())                                    #Removing underscore and Uppercasing first letter\n",
    "    \n",
    " return award_namelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIfQCd_Y1x5B"
   },
   "source": [
    "---\n",
    "\n",
    "## Task 5: Combining information in the output (5 Marks)\n",
    "\n",
    "Edit the function below to return a Python dictionary with the outputs from the functions defined in tasks $3 - 4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BE_8ptxp-1y4",
    "outputId": "db465b50-8544-4b12-851e-3e58a83a6ff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Directed by': ['George Lucas'],\n",
       " 'Produced by': ['Lucasfilm'],\n",
       " 'Task 4': [],\n",
       " 'Written by': ['George Lucas']}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_info(document):\n",
    "  '''Extract information and relations from a given document.'''\n",
    "\n",
    "  # Edit the output dict below and assign the values to keys by \n",
    "  # calling the appropriate functions from Tasks 3 and 4.\n",
    "  \n",
    "  # You can delete the keys for which you do not perform extraction in Task 3.\n",
    "\n",
    "  output = {\n",
    "    ##### EDIT BELOW THIS LINE #####\n",
    "    \n",
    "    # For the relations you extract in Task 3, \n",
    "    # save the output in the appropriate key and delete rest of the keys.\n",
    "   # \"Distribution companies\": extract_distribution_name(document),\n",
    "    \"Directed by\": extract_director_name(document),\n",
    "    \"Written by\": extract_writer_name(document),\n",
    "    \"Produced by\": extract_producer_name(document),\n",
    "\n",
    "    # save the output from Task 4 here\n",
    "    \"Task 4\": extract_award_names(document)\n",
    "\n",
    "    ##### EDIT ABOVE THIS LINE #####\n",
    "  }\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "# check output for the first document\n",
    "extract_info(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHv5pRQ7BKJo"
   },
   "source": [
    "The output from the cell above should look something like the dictionary shown below. Overall values might be different, based on what four items you choose to extract in Tasks 3 and 4, but the structure should be similar.\n",
    "\n",
    "For example, if you choose to extract **Starring**, **Release Date**, **Box office**, and **Directed by**, then the output should look something like this for the first document:\n",
    "\n",
    "```javascript\n",
    "{\n",
    "  'Box office': ['$775 million'],\n",
    "  'Directed by': ['George Lucas'],\n",
    "  'Release date': ['May 25, 1977'],\n",
    "  'Starring': ['Mark Hamill', 'Harrison Ford', 'Carrie Fisher', \n",
    "               'Peter Cushing', 'David Prowse', 'James Earl Jones', ],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDMhFQq4fBnf"
   },
   "source": [
    "---\n",
    "\n",
    "## Task 6: Evaluation (I) (15 Marks)\n",
    "\n",
    "Write a function to evaluate the performance of Task $3$ using **Precision**, **Recall** and **F1** scores. Use the gold-standard labels provided in the JSON files to calculate these values.\n",
    "\n",
    "Please note that not all the information / relations mentioned in Task $3$ have associated labels for each and every movie in the JSON documents, i.e., some JSON documents will have certain keys-value pairs missing. For example, we have labels for *Budget* in 46 out of the 50 movies and in the remaining 4 documents, you will find that the key `Budget` is omitted from the JSON.\n",
    " \n",
    "Also keep in mind that we will further run this evaluation on a hidden test set containing similar movie descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "OvJ9OhnDe7ML"
   },
   "outputs": [],
   "source": [
    "def evaluate(labels, predictions):\n",
    "  '''\n",
    "  Evaluate the performance of relation extraction \n",
    "  using Precision, Recall, and F1 scores.\n",
    "\n",
    "  Args:\n",
    "    labels: A list containing gold-standard labels\n",
    "    predictions: A list containing information extracted from documents\n",
    "  Returns:\n",
    "    scores: A dictionary containing Precision, Recall and F1 scores \n",
    "            for the information/relations extracted in Task 3.\n",
    "  '''\n",
    "\n",
    "  assert len(predictions) == len(labels)\n",
    "\n",
    "  scores = {\n",
    "      'precision': 0.0, 'recall': 0.0, 'f1': 0.0\n",
    "  }\n",
    "\n",
    "  # calculate the precision, recall and f1 score over the information fields \n",
    "  # corresponding to Task 3 and store the result in the `scores` dict.\n",
    "\n",
    "  # your code goes here\n",
    "  # ...\n",
    "  true_positive_value = 0\n",
    "  predicted_positive_value = 0\n",
    "  actual_positive_value = 0\n",
    "  \n",
    "  for pred_value, lbl_value in zip(predictions, labels):\n",
    "    for dict_key, dict_value in pred_value.items():\n",
    "      if dict_key!=\"Task 4\":\n",
    "        set_1 = set(pred_value[dict_key])\n",
    "      if dict_key in lbl_value:\n",
    "          set_2 = set(lbl_value[dict_key])\n",
    "          true_positive_value = true_positive_value + len(set_1.intersection(set_2))\n",
    "          predicted_positive_value = predicted_positive_value + len(set(pred_value[dict_key]))\n",
    "          actual_positive_value = actual_positive_value + len(set(lbl_value[dict_key]))\n",
    "\n",
    "  scores['precision'] = true_positive_value / predicted_positive_value\n",
    "  scores['recall'] = true_positive_value / actual_positive_value\n",
    "  scores['f1'] = 2 * (scores['precision'] * scores['recall']) / (scores['precision'] + scores['recall']) \n",
    "\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA39EbBCfRu6"
   },
   "source": [
    "---\n",
    "Run the cell below to calculate and display the evaluation scores for the 50 documents in `movies.zip`.\n",
    "\n",
    "You can consider the following as a baseline score. Your aim should be to score higher or atleast get as close as possible to these values.\n",
    "\n",
    "| Precision | Recall | F1    |\n",
    "| :---:     | :---:  | :---: |\n",
    "| 0.5       | 0.25   | 0.333 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "CRxOd4dIfRu-",
    "outputId": "178d02a3-d559-4321-ecc5-ff2abcee9e54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-57c2dad6-db5f-454c-bbaf-6d92d38eede8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.368601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57c2dad6-db5f-454c-bbaf-6d92d38eede8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-57c2dad6-db5f-454c-bbaf-6d92d38eede8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-57c2dad6-db5f-454c-bbaf-6d92d38eede8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   precision    recall        f1\n",
       "0   0.683544  0.252336  0.368601"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "# calculate evaluation score across all the 50 documents\n",
    "extracted_infos = []\n",
    "for document in documents:\n",
    "  extracted_infos.append(extract_info(document))\n",
    "\n",
    "scores = evaluate(labels, extracted_infos)\n",
    "\n",
    "pd.DataFrame([scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agNQPVqG5aoS"
   },
   "source": [
    "---\n",
    "\n",
    "## Task 7: Evaluation (II) (10 Marks)\n",
    "\n",
    "Describe **two** challenges you encountered above or might encounter in the evaluation of *information extraction* or *relation extraction* tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfdKI5J-fF1g"
   },
   "source": [
    "Edit this cell to write your answer below the line in no more than 100 words. No coding is required for this task.\n",
    "\n",
    "---\n",
    "\n",
    "> \n",
    "\n",
    "**Ambiguity** -\n",
    "computers lack the cognitive capability like humans to interpret the meaning easily based on their knowledge.\n",
    "Consider relations 'Produced by' and 'Production companies’ which are extracted using a common pattern \"produced”. But it's fetching producer name in doc 3 and retrieving “Marvel Studios\"(production company name) in doc 4, resulting less precision score.\n",
    "\n",
    "**Term mismatch**-\n",
    "Some of the terms specified in the gold-standard labels are officially defined, but similar words in the corpus are conventionally defined, resulting in a mismatch, for example. Although \"Lucasfilm Ltd.\" is stated in JSON file, it is referred to as \"Lucasfilm\" in corpus.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "21238848_Shinde_Assignment_03 (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
